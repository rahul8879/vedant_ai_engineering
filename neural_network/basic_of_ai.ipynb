{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d03b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff2076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
       "0                5.1               3.5  ...               0.2       0\n",
       "1                4.9               3.0  ...               0.2       0\n",
       "2                4.7               3.2  ...               0.2       0\n",
       "3                4.6               3.1  ...               0.2       0\n",
       "4                5.0               3.6  ...               0.2       0\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets load the dataset - dataframe format\n",
    "data = load_iris(as_frame=True)\n",
    "df = data.frame\n",
    "df.head()\n",
    "# here 0 means setosa, 1 means versicolor and 2 means virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afa89ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807ae953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use the logistic regression model : from scratch\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_predicted = self._sigmoid(linear_model)\n",
    "\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self._sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return np.array(y_predicted_cls)\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8351ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Weights: [ 46.33164538 -18.48741776 131.28611458  56.89643471]\n",
      "Bias: -0.7752707150257157\n"
     ]
    }
   ],
   "source": [
    "# use the model\n",
    "model = LogisticRegression(learning_rate=0.1, n_iterations=1000)\n",
    "model.fit(X_train.values, y_train.values)\n",
    "predictions = model.predict(X_test.values)\n",
    "print(\"Predictions:\", predictions) \n",
    "\n",
    "# lets see the weights and bias\n",
    "print(\"Weights:\", model.weights)\n",
    "print(\"Bias:\", model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84596a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "# use sklearn model\n",
    "sklearn_model = LogisticRegression()\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "sklearn_predictions = sklearn_model.predict(X_test)\n",
    "print(\"Sklearn Predictions:\", sklearn_predictions)\n",
    "# accuracy\n",
    "accuracy = np.sum(sklearn_predictions == y_test.values) / len(y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2898d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the model\n",
    "import pickle\n",
    "with open('logistic_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(sklearn_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96ff93cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Weights: [[-0.39349364  0.96246717 -2.3751418  -0.99874814]\n",
      " [ 0.50845582 -0.25479812 -0.21300858 -0.77574559]\n",
      " [-0.11496218 -0.70766905  2.58815039  1.77449373]]\n"
     ]
    }
   ],
   "source": [
    "# lets see the weights and bias of sklearn model\n",
    "print(\"Sklearn Weights:\", sklearn_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fc45118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Sklearn Predictions: [1 0 2 1 1 0 1 2 1 1 1 0 0 0 0 1 2 1 1 2 0 1 0 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahultiwari/Documents/02_Freelancing/Vedant_training/ai-env/lib/python3.13/site-packages/sklearn/utils/validation.py:2742: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# lets use Gradient descent to find the best value of weights and bias\n",
    "def gradient_descent(X, y, model, learning_rate=0.01, n_iterations=1000):\n",
    "    m = X.shape[0]\n",
    "    for i in range(n_iterations):\n",
    "        model.fit(X, y)\n",
    "        # Compute gradients\n",
    "        gradients = model.coef_\n",
    "        # Update weights\n",
    "        model.coef_ -= learning_rate * gradients\n",
    "    return model\n",
    "\n",
    "# Using gradient descent to optimize sklearn model\n",
    "optimized_model = gradient_descent(X_train.values, y_train.values, sklearn_model, learning_rate\n",
    "=0.1, n_iterations=1000)\n",
    "optimized_predictions = optimized_model.predict(X_test)\n",
    "print(\"Optimized Sklearn Predictions:\", optimized_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8705212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Sklearn Weights: [[-0.35414428  0.86622045 -2.13762762 -0.89887332]\n",
      " [ 0.45761024 -0.22931831 -0.19170773 -0.69817103]\n",
      " [-0.10346596 -0.63690215  2.32933535  1.59704436]]\n"
     ]
    }
   ],
   "source": [
    "# weights after optimization\n",
    "print(\"Optimized Sklearn Weights:\", optimized_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4979e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
